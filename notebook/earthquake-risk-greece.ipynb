{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake risk in Greece\n",
    "\n",
    "This project is quite different from a software development task.\n",
    "\n",
    "Don't hesitate to contact us, if you have any doubts on what is asked or if you encounter error will using the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "\n",
    "+ ðŸš¨ Only cells with the comment `# NOTE: Fill me!` should be filled\n",
    "+ ðŸš¨ Notebook should be saved and commited **with** outputs for the submission\n",
    "\n",
    "\n",
    "+ âš ï¸ The solution only requires packages listed in the `requirements/requirements.txt`\n",
    "+ âš ï¸ Unit tests should be favored when asked to write tests \n",
    "+ âš ï¸ Tests must automatically be detected running `pytest`\n",
    "+ âš ï¸ Requested method signature should be inferred from this notebook\n",
    "\n",
    "\n",
    "## Note\n",
    "\n",
    "+ The `assert` statements in the notebook are here to guide the project.\n",
    "However, successful `assert` statements does not guaranty that your code is correct.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In a Python >= 3.8 virtual env, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r ../requirements/requirements.txt\n",
    "! pip install --no-deps -e .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd .. && pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "A client asks for an insurance of their asset, located at `(35.025, 25.763)` in Greece.\n",
    "\n",
    "The client wishes to receive a payout under the following conditions:\n",
    "\n",
    "+ earthquake of magnitude `4.5` or higher within `10km`: full payout\n",
    "+ earthquake of magnitude `5.5` or higher within `50km`: `75%` payout\n",
    "+ earthquake of magnitude `6.5` or higher within `200km`: `50%` payout\n",
    "\n",
    "In the event of aftershocks, a payout can only occur once a year using the maximal value.\n",
    "\n",
    "## Example\n",
    "\n",
    "If in the same year:\n",
    "\n",
    "* an earthquake of magnitude `6.8` occurs within `200km`\n",
    "* **and** an aftershock of magnitude `5.8` occurs within `50km`\n",
    "\n",
    "the client receives a `75%` payout, and not a `125%` payout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from earthquakes.tools import (\n",
    "    DISTANCE_COLUMN,\n",
    "    LATITUDE_COLUMN,\n",
    "    LONGITUDE_COLUMN,\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake data\n",
    "\n",
    "The US Geological Service (USGS) provides CSV data through their [API](https://earthquake.usgs.gov/fdsnws/event/1/).\n",
    "\n",
    "Use it to retrieve earthquake information.\n",
    "\n",
    "In the module `earthquakes.usgs_api`:\n",
    "+ Implement the function `get_earthquake_data`,\n",
    "+ The function will retrieve the earthquake data of the area of interest for the past 200 years,\n",
    "+ The implementation must use the `urllib` python package,\n",
    "+ The API request url must be build in a dedicated function `build_api_url`,\n",
    "+ Tests should be provided for `build_api_url`.\n",
    "\n",
    "Note: Earthquakes after the 21-10-2021 should not be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthquakes.usgs_api import get_earthquake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Fill me!\n",
    "\n",
    "latitude = \"fill with proper object\"\n",
    "longitude = \"fill with proper object\"\n",
    "radius = \"fill with proper object\"\n",
    "minimum_magnitude = \"fill with proper object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This request may take significant time (>10s)\n",
    "earthquake_data = get_earthquake_data(\n",
    "    latitude=latitude,\n",
    "    longitude=longitude,\n",
    "    radius=radius,\n",
    "    minimum_magnitude=minimum_magnitude,\n",
    "    end_date=datetime(year=2021, month=10, day=21)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(earthquake_data, pd.DataFrame)\n",
    "assert len(earthquake_data) == 656"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning\n",
    "\n",
    "The next test may fail because USGS regularly updates their earthquake database.\n",
    "\n",
    "The dataframe obtained should over be similar to that presented bellow.\n",
    "\n",
    "Please contact us if there is an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_earthquake_data = pd.DataFrame([\n",
    "        [\"2021-10-12T09:24:05.099Z\", 35.1691, 26.2152, 20.0, 6.4, \"mww\", np.nan, 19.0, 0.860, 0.46,\"us\", \"us6000ftxu\", \"2021-12-18T19:58:57.040Z\", \"4 km SW of Palekastro, Greece\", \"earthquake\", 6.1, 1.8, 0.048, 42.0, \"reviewed\", \"us\", \"us\"],\n",
    "        [\"2021-10-03T14:31:27.622Z\", 35.1442, 25.2375, 10.0, 4.6, \"mb\", np.nan, 119.0, 0.318, 0.64, \"us\", \"us6000fsp1\", \"2021-12-10T21:14:19.040Z\", \"2 km W of ArkalochÃ³ri, Greece\", \"earthquake\", 5.0, 1.9, 0.165, 13.0, \"reviewed\", \"us\", \"us\"],\n",
    "        [\"2021-09-29T11:54:48.885Z\", 35.0268, 25.1561, 10.0, 4.6, \"mb\", np.nan, 69.0, 0.339, 0.83, \"us\", \"us6000fq3y\", \"2021-12-04T14:27:58.040Z\", \"2 km N of PÃ½rgos, Greece\", \"earthquake\", 5.1, 1.3, 0.068, 64.0, \"reviewed\", \"us\", \"us\"],\n",
    "        [\"2021-09-28T15:13:16.867Z\", 35.2054, 25.2791, 10.0, 4.7, \"mb\", np.nan, 58.0, 0.329, 0.70, \"us\", \"us7000ff84\", \"2021-12-04T14:30:09.040Z\", \"1 km N of ThrapsanÃ³n, Greece\", \"earthquake\", 6.9, 1.8, 0.067, 73.0, \"reviewed\", \"us\", \"us\"],\n",
    "        [\"2021-09-28T04:48:08.650Z\", 35.0817, 25.2018, 10.0, 5.3, \"mww\", np.nan, 43.0, 0.328, 0.94, \"us\", \"us7000ff36\", \"2021-12-04T14:30:04.040Z\", \"9 km SW of ArkalochÃ³ri, Greece\", \"earthquake\", 4.5, 1.7, 0.046, 45.0, \"reviewed\", \"us\", \"us\"],\n",
    "    ],\n",
    "    columns=['time', 'latitude', 'longitude', 'depth', 'mag', 'magType', 'nst', 'gap', 'dmin', 'rms', 'net', 'id', 'updated', 'place', 'type', 'horizontalError', 'depthError', 'magError', 'magNst', 'status', 'locationSource', 'magSource']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_data_sample = earthquake_data[\n",
    "    earthquake_data[\"time\"].isin(expected_earthquake_data[\"time\"])\n",
    "]\n",
    "\n",
    "pd.testing.assert_frame_equal(earthquake_data_sample, expected_earthquake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance\n",
    "\n",
    "We wish to compute the the historical payouts (i.e. the payouts that would have occurred for the past 200 years).\n",
    "\n",
    "To compute the historical payouts, we need to know the distance between each earthquake and our client's asset.\n",
    "\n",
    "The distance between two points on a sphere is the [Haversine distance](https://en.wikipedia.org/wiki/Haversine_formula). In the module `eathquakes.tools`:\n",
    "- Implement and test the function `get_haversine_distance`,\n",
    "- Use `earthquakes.tools.EARTH_RADIUS` (6378km) as an approximation of the radius of Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthquakes.tools import get_haversine_distance\n",
    "\n",
    "distances = get_haversine_distance(earthquake_data[LATITUDE_COLUMN], earthquake_data[LONGITUDE_COLUMN], latitude, longitude)\n",
    "\n",
    "earthquake_data[DISTANCE_COLUMN] = distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical payouts and burning costs\n",
    "\n",
    "### Payout\n",
    "\n",
    "The historical payouts are a map `year -> payout in %`.\n",
    "\n",
    "eg: `1950: 50` for a payout of `50%` in 1950.\n",
    "\n",
    "Payouts are NOT given per event, but per year.\n",
    "\n",
    "This map can take the form of a python `dict` or of a pandas `Series`. \n",
    "\n",
    "### Burning cost\n",
    "\n",
    "The `burning cost` is the average of payouts over a time range.\n",
    "\n",
    "In this project, the burning cost should be expressed in `%`. \n",
    "\n",
    "### Payout structure\n",
    "\n",
    "The payout structure is:\n",
    "\n",
    "| Radius | Magnitude | Payout |\n",
    "|--------|-----------|--------|\n",
    "| 10km   | 4.5       | 100 %  |\n",
    "| 50km   | 5.5       |  75 %  |\n",
    "| 200km  | 6.5       |  50 %  |\n",
    "\n",
    "Payouts can occur only once in a given year.\n",
    "\n",
    "In the module `earthquakes.tools`:\n",
    "+ Implement the functions `compute_payouts` and `compute_burning_cost`,\n",
    "+ Tests for these functions are not required.\n",
    "\n",
    "### Example\n",
    "\n",
    "A payout `{1950: 50, 1992: 75}` means that we would have paid our client\n",
    "+ in 1950, for `50%` of the insured amount (called 'limit')\n",
    "+ in 1992, for `75%` of the limit\n",
    "\n",
    "The burning cost over the `1922-2021` period would be `1.25%`.\n",
    "\n",
    "The burning cost over the `1972-2021` period would be `1.5%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthquakes.tools import compute_payouts, compute_burning_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Fill me!\n",
    "\n",
    "payout_structure = \"fill with proper object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payouts = compute_payouts(earthquake_data, payout_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the return type of compute_payouts, the following line needs to be adjusted.\n",
    "# - pd.Series:\n",
    "payout_values = np.array(payouts.values)\n",
    "# - dict:\n",
    "# payout_values = np.array(list(payouts.values()))\n",
    "assert np.max(payout_values) > 1\n",
    "assert np.max(payout_values) <= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burning_cost = compute_burning_cost(payouts, start_year=1952, end_year=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(burning_cost, 10.71, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1921, 2021)\n",
    "plt.plot(\n",
    "    years, \n",
    "    [\n",
    "        compute_burning_cost(payouts, start_year=start_year, end_year=2021) \n",
    "        for start_year in years\n",
    "    ]\n",
    ")\n",
    "plt.gca().invert_xaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large asset portfolio - async requests\n",
    "\n",
    "Our client also whishes to cover a large amount of properties all over Europe.\n",
    "\n",
    "In order to speed-up the requests to the USGS API, in the module `earthquakes.usgs_api`:\n",
    "- Implement the `async` function `get_earthquake_data_for_multiple_locations`,\n",
    "- The implementation should use the `asyncio` and `aiohttp` libraries,\n",
    "- The solution should re-use some of the functions already written,\n",
    "- Tests are not required for any of the functions.\n",
    "\n",
    "Note: it is possible that the notebook autoreload feature doesn't work for `async` functions - a kernel restart may be necessary after each modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from earthquakes.tools import (\n",
    "    LATITUDE_COLUMN,\n",
    "    LONGITUDE_COLUMN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_assets = 10\n",
    "# NOTE: limiting to number of assets so that the query doesn't take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "random_values = random_state.random(2*number_of_assets)\n",
    "\n",
    "latitudes = random_values[::2] * 20 + 35.0\n",
    "longitudes = random_values[1::2] * 25 + 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthquakes.usgs_api import get_earthquake_data_for_multiple_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Fill me!\n",
    "assets = \"fill with proper object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This request may take significant time (>10s)\n",
    "earthquake_data = await get_earthquake_data_for_multiple_locations(  # type: ignore\n",
    "    assets, \n",
    "    radius=200, \n",
    "    minimum_magnitude=4.5, \n",
    "    end_date=datetime(year=2021, month=10, day=21)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(earthquake_data, pd.DataFrame)\n",
    "assert len(earthquake_data) == 1036"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60230ecbd9b9a94ff1397bcfe0cbc26fc23c06e2385a718caf30b052d5019f5e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
